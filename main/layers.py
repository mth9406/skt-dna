import torch
from torch import nn 
from torch.nn import functional as F

from utils import *

def make_input_n_mask_pairs(x, device): 
    r"""A fucntion to make pairs of input-mask

    # Arguments
    ____________
    x : dict 
        x['input']: input time-series
        x['mask']: indicator 
    
    # Returns
    _________
    pair : torch-Tensor 
        the shape of the tensor 'pair' is b, 2*c, t, n 
        where:          
            b= batch size of the x['input']          
            c= # chennels of the x['input']        
            t= # time-stamps of the x['input']        
            n= # time-series of the x['input']                           
    """
    b, c, n, p =  x['input'].shape # batch_size, #channel, #time-series, #time-stamps
    pair = torch.zeros((b,2*c,n,p)).to(device)
    pair[:, ::2, ...] = x['input'] 
    pair[:, 1::2, ...] = x['mask']
    return pair

class ResidualAdd(nn.Module):
    r"""Residual connection

    # Arguments
    ____________
    fn : sub-class of nn.Module          
    
    # Returns
    _________
    returns residual connection           
    """
    def __init__(self, fn):
        super().__init__()
        self.fn = fn

    def forward(self, x, **kwargs):
        res = x
        x = self.fn(x, **kwargs)
        x += res
        return x

# projection layer
class ProjectionConv1x1Layer(nn.Module): 
    r"""Projection layer using conv1x1
    """
    def __init__(self, in_channels, out_channels, groups, **kwargs): 
        super().__init__()     
        self.projection = nn.Conv2d(in_channels, out_channels, 1, 1, 0, 1, groups= groups, **kwargs)
        self.in_channels, self.out_channels = in_channels, out_channels 

    def forward(self, pair): 
        r"""Feed forward

        pair : torch-Tensor
            generated by the function: make_input_n_mask_pairs(x)
            the shape of the tensor 'pair' is b, 2*c, t, n 
        """
        return self.projection(pair)

class CausalDilatedVerticalConv1d(nn.Module): 
    r"""Causal dilated convoltion
    Causal dilated convolution is based on the work by
    \"""
    Oord, A. V. D., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). 
    Wavenet: A generative model for raw audio. 
    arXiv preprint arXiv:1609.03499.
    \"""
    This module only defers from the original work inthat 
    (1) it is a group-wise convolution 
    (2) the kernel 'moves' vertically.
    """
    def __init__(self, 
                in_channels, out_channels, 
                kernel_size,  
                groups, dilation, 
                **kwargs
                ): 
        assert kernel_size[1] == 1, "kernel[1] should have size 1."
        super().__init__()
        self.pad = (kernel_size[0] - 1) * dilation 
        self.causal_conv = nn.Conv2d(in_channels, out_channels, kernel_size, 
                                        padding= (self.pad, 0), dilation= dilation, groups= groups, **kwargs)

        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size 
        self.groups = groups 
        self.dilation = dilation

    def forward(self, x): 
        x = self.causal_conv(x) 
        x = x[..., :-self.causal_conv.padding[0], :] if self.pad > 0 else x
        return x

# temporal convolution layer
class DilatedInceptionLayer(nn.Module):
    r"""Dilated inception layer
    """
    def __init__(self, in_channels, out_channels, **kwargs):
        super().__init__()
        self.branch1x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (1,1), in_channels, 1, **kwargs)
        self.branch3x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 1, **kwargs)
        self.branch5x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 2, **kwargs)
        self.branch7x1 = CausalDilatedVerticalConv1d(in_channels, out_channels, (3,1), in_channels, 3, **kwargs)

        self.in_channels, self.out_channels = in_channels, out_channels

    def forward(self, x): 
        b, c, n, p = x.shape
        outs = torch.zeros(b, 4*c, n, p).to(x.device)
        for i in range(4): 
            branch = getattr(self, f'branch{2*i+1}x1')
            outs[:, i::4, ...] = branch(x) 
            # we have c groups of receptive channels...
            # = 4 channels form one group.
        return outs

class TemporalConvolutionModule(nn.Module): 
    r"""TemporalConvolutionModule
    """
    def __init__(self, in_channels, out_channels, num_heteros, **kwargs): 
        super().__init__()
        self.dil_filter = DilatedInceptionLayer(in_channels, out_channels, **kwargs)
        self.dil_gate = DilatedInceptionLayer(in_channels, out_channels, **kwargs) 
        self.conv_inter = nn.Conv2d(4*in_channels, in_channels, 1, groups= num_heteros, **kwargs)
        self.in_channels, self.out_channels = in_channels, out_channels  
        self.num_heteros = num_heteros

    def forward(self, x): 
        out_filter = torch.tanh(self.dil_filter(x))
        out_gate = torch.sigmoid(self.dil_gate(x)) 
        out = out_filter*out_gate
        return self.conv_inter(out)        

# graph convolution layer 
class InformationPropagtionLayer(nn.Module): 
    r"""Information Propagtion Layer
    """
    def __init__(self): 
        super().__init__() 

    def forward(self, x, h_in, A_inter, beta= 0.5): 
        r"""Feed forward
        x : FloatTensor
            input time series 
        A_inter : C x N x N 
            adjacency matrix (inter time series)
        A_outer : C x C 
            adjacency matrix (outer time series)
            yet to be used...
        """
        # obtain normalized adjacency matrices
        # A_i = self.norm_adj(A_inter)
        h = torch.matmul(x, A_inter) # bs, c, t, n 
        # h = self.beta * x + (1-self.beta) * h
        return beta * h_in + (1-beta) * h
        
# graph convolution module 
class GraphConvolutionModule(nn.Module): 
    r"""Graph convolution module
    # Arguments
    ____________
    in_features : int
        dimension of the input tensor
    out_features : int
        dimension of the output tensor 
    k : int
        the number of layers (hops)
    """
    def __init__(self, in_features, out_features, k, **kwargs): 
        super().__init__() 
        # self.conv_inter = nn.Conv2d(in_features, out_features, 1, groups= out_features, **kwargs)

        for i in range(1, k+1):
            setattr(self, f'gcl{i}', InformationPropagtionLayer())

        for i in range(k+1): 
            setattr(self, f'info_select{i}', nn.Conv2d(out_features, out_features, 1,1,0,1, groups= out_features, bias= False, **kwargs))
        
        self.in_features, self.out_features, self.k\
            = in_features, out_features, k
    
    def forward(self, x, A, beta= 0.5):
        A_tilde = self.norm_adj(A)
        A_tilde_after = A_tilde
        # x = self.conv_inter(x)
        hiddens = [x]
        gcl = getattr(self, 'gcl1')
        hiddens.append(gcl(hiddens[-1], x, A_tilde))
        for i in range(2, self.k+1): 
            gcl = getattr(self, f'gcl{i}')
            A_tilde_after = torch.matmul(torch.transpose(A_tilde_after,-1,-2), A_tilde)
            hiddens.append(gcl(hiddens[-1], x, A_tilde_after, beta= beta))
        out = 0
        for i in range(self.k+1):
            info_select = getattr(self, f'info_select{i}')
            out += info_select(hiddens[i])
        return out 

    def norm_adj(self, A): 
        r"""Obtains normalized version of an adjacency matrix
        """
        if len(A.shape) == 3 or len(A.shape) == 2:
            with torch.no_grad():
                if len(A.shape) == 3: 
                    eyes = torch.stack([torch.eye(A.shape[1]) for _ in range(A.shape[0])]).to(device= A.device)
                    D_tilde_inv = torch.diag_embed(1/(1. + torch.sum(A, dim=1))) # C x N x N 
                    A_tilde = D_tilde_inv @ (A + eyes)
                else: 
                    eye = torch.eye(A.shape[1]).to(A.device)
                    D_tilde_inv = torch.diag(1/(1.+torch.sum(A, dim=1)))
                    A_tilde = D_tilde_inv @ (A + eye)
            return A_tilde 
        else: 
            return A

class HeteroBlock(nn.Module):
    r"""Hetero block 
    This block contains TC-Module + GC-Module and its residual connection.

    # Arguments
    ___________
    num_heteros : int
        the number of heterogeneous groups
    k : int 
        the number of layers at every GC-Module
    It takes the followings in the feed-forward procedures.
    * Adjacency matrix from the 'Graph-Learning-Layer' 
    * Another input from the previous 'HeteroBlock' module
    
    # Returns
    _________
    It returns two outputs 
    * output from TC-Module
    * output from GC-Module which takes an output of TC-Module as an input.
    """
    def __init__(self, num_heteros:int, k:int, **kwargs): 
        super().__init__() 
        self.tc_module = TemporalConvolutionModule(num_heteros, num_heteros, num_heteros, **kwargs)
        self.gc_module = GraphConvolutionModule(num_heteros, num_heteros, k=k, **kwargs)
        self.gc_module_t = GraphConvolutionModule(num_heteros, num_heteros, k=k, **kwargs)

        self.num_heteros = num_heteros
        self.k = k 
        # input shape: b, c, n, l 

    def forward(self, x, A, beta= 0.5): 
        r"""Feed forward        
        returns two outputs
        * output from TC-Module
        * output from GC-Module which takes an output of TC-Module as an input.     

        # Arguments       
        ___________        
        x : torch-tensor        
            Input tensor             
        A : torch-tensor           
            Adjacency matrix        
        """
        res = x 
        out_tc = self.tc_module(x) 
        x = self.gc_module(out_tc, A, beta= beta)
        x += self.gc_module_t(out_tc, torch.transpose(A, -1, -2), beta= beta)
        return out_tc, F.gelu(x+res)
